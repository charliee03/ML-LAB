{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2972672c",
   "metadata": {},
   "source": [
    "# Case Study 1: Customer Churn Prediction (Classification)\n",
    "\n",
    "**Student Name:** [Your Name]  \n",
    "**SRN:** [Your SRN]  \n",
    "**Dataset:** customer_churn_data.csv  \n",
    "**Objective:** Predict customer churn using classification algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab660ad8",
   "metadata": {},
   "source": [
    "## Task 1: Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0833a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0fbfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('customer_churn_data.csv')\n",
    "\n",
    "# Basic information about the dataset\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfff25d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520be842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbf282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23495d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "print(\"Data Types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e66a1fa",
   "metadata": {},
   "source": [
    "## Task 2: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a5bb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze churn distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "churn_counts = df['churn'].value_counts()\n",
    "plt.pie(churn_counts.values, labels=churn_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Churn Distribution')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.countplot(data=df, x='churn')\n",
    "plt.title('Churn Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate churn rate\n",
    "churn_rate = (df['churn'] == 'Yes').mean() * 100\n",
    "print(f\"Churn Rate: {churn_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f166e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographic patterns analysis\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Age distribution by churn\n",
    "plt.subplot(2, 3, 1)\n",
    "sns.boxplot(data=df, x='churn', y='age')\n",
    "plt.title('Age Distribution by Churn')\n",
    "\n",
    "# Gender analysis\n",
    "plt.subplot(2, 3, 2)\n",
    "sns.countplot(data=df, x='gender', hue='churn')\n",
    "plt.title('Gender vs Churn')\n",
    "\n",
    "# Senior citizen analysis\n",
    "plt.subplot(2, 3, 3)\n",
    "sns.countplot(data=df, x='senior_citizen', hue='churn')\n",
    "plt.title('Senior Citizen vs Churn')\n",
    "\n",
    "# Partner analysis\n",
    "plt.subplot(2, 3, 4)\n",
    "sns.countplot(data=df, x='partner', hue='churn')\n",
    "plt.title('Partner vs Churn')\n",
    "\n",
    "# Dependents analysis\n",
    "plt.subplot(2, 3, 5)\n",
    "sns.countplot(data=df, x='dependents', hue='churn')\n",
    "plt.title('Dependents vs Churn')\n",
    "\n",
    "# Tenure analysis\n",
    "plt.subplot(2, 3, 6)\n",
    "sns.boxplot(data=df, x='churn', y='tenure')\n",
    "plt.title('Tenure vs Churn')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499dfa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service usage impact analysis\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Internet service\n",
    "plt.subplot(2, 3, 1)\n",
    "sns.countplot(data=df, x='internet_service', hue='churn')\n",
    "plt.title('Internet Service vs Churn')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Contract type\n",
    "plt.subplot(2, 3, 2)\n",
    "sns.countplot(data=df, x='contract', hue='churn')\n",
    "plt.title('Contract Type vs Churn')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Payment method\n",
    "plt.subplot(2, 3, 3)\n",
    "sns.countplot(data=df, x='payment_method', hue='churn')\n",
    "plt.title('Payment Method vs Churn')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Phone service\n",
    "plt.subplot(2, 3, 4)\n",
    "sns.countplot(data=df, x='phone_service', hue='churn')\n",
    "plt.title('Phone Service vs Churn')\n",
    "\n",
    "# Paperless billing\n",
    "plt.subplot(2, 3, 5)\n",
    "sns.countplot(data=df, x='paperless_billing', hue='churn')\n",
    "plt.title('Paperless Billing vs Churn')\n",
    "\n",
    "# Multiple lines\n",
    "plt.subplot(2, 3, 6)\n",
    "sns.countplot(data=df, x='multiple_lines', hue='churn')\n",
    "plt.title('Multiple Lines vs Churn')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634fd9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Financial factors analysis\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Monthly charges\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(data=df, x='churn', y='monthly_charges')\n",
    "plt.title('Monthly Charges vs Churn')\n",
    "\n",
    "# Total charges\n",
    "plt.subplot(1, 3, 2)\n",
    "# Convert total_charges to numeric (it might be stored as string)\n",
    "df['total_charges'] = pd.to_numeric(df['total_charges'], errors='coerce')\n",
    "sns.boxplot(data=df, x='churn', y='total_charges')\n",
    "plt.title('Total Charges vs Churn')\n",
    "\n",
    "# Customer satisfaction\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(data=df, x='churn', y='customer_satisfaction')\n",
    "plt.title('Customer Satisfaction vs Churn')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6e9cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis for numerical features\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = df[numerical_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, square=True)\n",
    "plt.title('Correlation Matrix of Numerical Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ef9dba",
   "metadata": {},
   "source": [
    "## Task 3: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ba5e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for preprocessing\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Handle any missing values in total_charges\n",
    "df_processed['total_charges'].fillna(0, inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = df_processed.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in categorical_columns:\n",
    "    if col != 'customer_id':  # Don't encode customer_id\n",
    "        le = LabelEncoder()\n",
    "        df_processed[col] = le.fit_transform(df_processed[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "print(\"Categorical variables encoded:\")\n",
    "print(list(label_encoders.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeccc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering - create new features if beneficial\n",
    "# Average monthly charges per tenure month\n",
    "df_processed['avg_monthly_charges'] = df_processed['total_charges'] / (df_processed['tenure'] + 1)\n",
    "\n",
    "# High value customer (above median total charges)\n",
    "median_charges = df_processed['total_charges'].median()\n",
    "df_processed['high_value_customer'] = (df_processed['total_charges'] > median_charges).astype(int)\n",
    "\n",
    "print(\"New features created:\")\n",
    "print(\"- avg_monthly_charges\")\n",
    "print(\"- high_value_customer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8ec77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "# Drop customer_id as it's not a feature\n",
    "X = df_processed.drop(['customer_id', 'churn'], axis=1)\n",
    "y = df_processed['churn']\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)\n",
    "print(\"\\nFeatures:\", list(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b51ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Validation set size:\", X_val.shape)\n",
    "print(\"Test set size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b22164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Features scaled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de3ccd1",
   "metadata": {},
   "source": [
    "## Task 4: Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da3e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'SVM': SVC(random_state=42)\n",
    "}\n",
    "\n",
    "# Hyperparameter grids\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'solver': ['liblinear', 'lbfgs']\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'max_depth': [5, 10, 15, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [5, 10, 15, None],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b888c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models with hyperparameter tuning\n",
    "best_models = {}\n",
    "training_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    # Grid search with cross-validation\n",
    "    grid_search = GridSearchCV(\n",
    "        model, \n",
    "        param_grids[name], \n",
    "        cv=5, \n",
    "        scoring='f1',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "    training_results[name] = {\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'best_score': grid_search.best_score_\n",
    "    }\n",
    "    \n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595f2367",
   "metadata": {},
   "source": [
    "## Task 5: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57ccb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models on validation set\n",
    "def evaluate_model(model, X, y, model_name):\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(y, y_pred),\n",
    "        'Precision': precision_score(y, y_pred),\n",
    "        'Recall': recall_score(y, y_pred),\n",
    "        'F1-Score': f1_score(y, y_pred)\n",
    "    }\n",
    "    \n",
    "    return metrics, y_pred\n",
    "\n",
    "# Evaluate all models\n",
    "validation_results = {}\n",
    "predictions = {}\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    metrics, y_pred = evaluate_model(model, X_val_scaled, y_val, name)\n",
    "    validation_results[name] = metrics\n",
    "    predictions[name] = y_pred\n",
    "    \n",
    "    print(f\"{name} - Validation Results:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f11cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "results_df = pd.DataFrame(validation_results).T\n",
    "print(\"Model Comparison (Validation Set):\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cfdea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Performance metrics comparison\n",
    "plt.subplot(2, 2, 1)\n",
    "results_df.plot(kind='bar', ax=plt.gca())\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Confusion matrices\n",
    "for i, (name, y_pred) in enumerate(predictions.items(), 1):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {name}')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    \n",
    "    if i == 3:  # Only show 3 confusion matrices due to space\n",
    "        break\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27f84c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best model based on F1-score\n",
    "best_model_name = results_df['F1-Score'].idxmax()\n",
    "best_model = best_models[best_model_name]\n",
    "\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Best F1-Score: {results_df.loc[best_model_name, 'F1-Score']:.4f}\")\n",
    "\n",
    "# Test on test set\n",
    "test_metrics, test_predictions = evaluate_model(best_model, X_test_scaled, y_test, best_model_name)\n",
    "\n",
    "print(f\"\\n{best_model_name} - Test Set Results:\")\n",
    "for metric, value in test_metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347f8531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final confusion matrix and classification report\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "cm_test = confusion_matrix(y_test, test_predictions)\n",
    "sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(f'Test Set Confusion Matrix - {best_model_name}')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Feature importance for tree-based models\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False).head(10)\n",
    "    \n",
    "    sns.barplot(data=feature_importance, x='importance', y='feature')\n",
    "    plt.title(f'Top 10 Feature Importances - {best_model_name}')\n",
    "    plt.xlabel('Importance')\n",
    "else:\n",
    "    plt.text(0.5, 0.5, f'{best_model_name}\\ndoes not have\\nfeature_importances_', \n",
    "             ha='center', va='center', transform=plt.gca().transAxes, fontsize=12)\n",
    "    plt.title('Feature Importance Not Available')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Detailed classification report\n",
    "print(f\"\\nDetailed Classification Report - {best_model_name}:\")\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1417b01d",
   "metadata": {},
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "### Key Findings:\n",
    "1. **Churn Rate**: [Add your analysis]\n",
    "2. **Best Model**: [Add best model name and performance]\n",
    "3. **Important Features**: [Add key features that influence churn]\n",
    "4. **Business Insights**: [Add actionable insights for reducing churn]\n",
    "\n",
    "### Model Performance:\n",
    "- **Best Model**: [Model name]\n",
    "- **Test Accuracy**: [Value]\n",
    "- **Test F1-Score**: [Value]\n",
    "- **Test Precision**: [Value]\n",
    "- **Test Recall**: [Value]\n",
    "\n",
    "### Recommendations:\n",
    "1. [Add recommendation 1]\n",
    "2. [Add recommendation 2]\n",
    "3. [Add recommendation 3]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
